#!/bin/bash

# Global env variables / defaults
: ${KUBERNETES_VERSION:=stable-1.7}

# Functions library
os_type() {
	cat /etc/*-release | grep '^NAME' | tr -d 'NAME="'
}

exists() {
	if command -v $1 >/dev/null 2>&1; then
		echo "Command $1 installed"
	else
		echo "Please install $1"
		exit 1
	fi
}

running_as_root() {
	if [[ $EUID > 0 ]]; then
  	echo "Please run as root/sudo"
  	exit 1
	fi
}

enable_bridge_iptables() {
	if [ "$(cat /proc/sys/net/bridge/bridge-nf-call-iptables)" == "0" ]; then
		echo "1" > /proc/sys/net/bridge/bridge-nf-call-iptables
	fi
}

config_docker_ubuntu() {
	cat << EOF > /etc/docker/daemon.json
{
	"storage-driver": "overlay"
}
EOF
	systemctl restart docker
}

config_docker_centos() {
	cat << EOF > /etc/docker/daemon.json
{
	"exec-opts": ["native.cgroupdriver=systemd"],
	"storage-driver": "overlay"
}
EOF
	systemctl restart docker
}

package_ubuntu() {
	apt-get update && apt-get install -y apt-transport-https
	curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -
	cat <<EOF >/etc/apt/sources.list.d/kubernetes.list
deb http://apt.kubernetes.io/ kubernetes-xenial main
EOF
	apt-get update
	# TODO: Until kubeadm 1.7.2 will be released, we can fix the kubeadm.conf issue by installing kubeadm=1.7.0-00
	apt-get install -y kubelet kubeadm=1.7.0-00
}

package_centos() {
	cat <<EOF > /etc/yum.repos.d/kubernetes.repo
[kubernetes]
name=Kubernetes
baseurl=https://packages.cloud.google.com/yum/repos/kubernetes-el7-x86_64
enabled=1
gpgcheck=1
repo_gpgcheck=1
gpgkey=https://packages.cloud.google.com/yum/doc/yum-key.gpg
        https://packages.cloud.google.com/yum/doc/rpm-package-key.gpg
EOF
	setenforce 0
	# TODO: Until kubeadm 1.7.2 will be released, we can fix the kubeadm.conf issue by installing kubeadm=1.7.0-00
	yum install -y kubelet kubeadm-1.7.0-0
	systemctl enable kubelet && systemctl start kubelet
}

# Phase 1 - Pre-flight checks

# 1. Are we running as root or sudo?
running_as_root

# 2. Docker exists?
exists "docker"

# 3. Nsenter utility exists?
exists "nsenter"

# Phase 2 - install kubernetes and kubeadm packages
case "$(os_type)" in
	*Ubuntu*)
		config_docker_ubuntu
		package_ubuntu
		;;
	*CentOS*|*Red*)
		enable_bridge_iptables
		config_docker_centos
		package_centos
		;;
	*)
		fail
		;;
esac

# Enable alpha APIs
cat <<EOF >/etc/kubernetes/kubeadm.conf
apiVersion: kubeadm.k8s.io/v1alpha1
kind: MasterConfiguration
kubernetesVersion: "$KUBERNETES_VERSION"
networking:
  podSubnet: 10.244.0.0/16
apiServerExtraArgs:
  "feature-gates": "PersistentLocalVolumes=true"
controllerManagerExtraArgs:
  "feature-gates": "PersistentLocalVolumes=true"
schedulerExtraArgs:
  "feature-gates": "AffinityInAnnotations=true"
EOF

# Phase 3 - initialize the Kubernetes cluster
kubeadm init --config /etc/kubernetes/kubeadm.conf | grep -P '^\[' --color=never

# Remove master taints to make master schedulable for pods
kubectl --kubeconfig /etc/kubernetes/admin.conf taint nodes --all dedicated-
kubectl --kubeconfig /etc/kubernetes/admin.conf taint nodes --all node-role.kubernetes.io/master-

# Install networking. Even in single-node mode, before the master node will become
# available for scheduling (Ready), it should detect a network plugin configuration.
kubectl --kubeconfig /etc/kubernetes/admin.conf create -f flannel.yml

# TODO: Move the addons such as the provisioner to the helm package
# Grant admin permissions to the default serviceaccount in the codefresh namespace
kubectl --kubeconfig /etc/kubernetes/admin.conf create namespace codefresh
kubectl --kubeconfig /etc/kubernetes/admin.conf create clusterrolebinding codefresh-default-cluster-admin --clusterrole=cluster-admin --serviceaccount=codefresh:default

# Create the host-path pvc provisioner
# Starting from Kubernetes version 1.7, a local provisioner plugin is supported, however it's still in alpha.
kubectl --kubeconfig /etc/kubernetes/admin.conf --namespace codefresh create -f local-storage.yml
mkdir -p /var/local-volume-provisioner/disks/{1..20}

cat << END
'Your single-node Kubernetes cluster has initialized successfully!"

To start using your cluster, you need to run (as a regular user):

  mkdir -p $HOME/.kube
  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
  sudo chown $(id -u):$(id -g) $HOME/.kube/config'

END

